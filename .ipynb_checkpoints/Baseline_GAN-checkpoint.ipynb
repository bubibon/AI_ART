{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W4CWJ7fTT7Vb",
    "outputId": "a537b597-bd58-4cc2-b81e-c0e23201cd51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WJv5C0XcVNqK",
    "outputId": "308ffc26-3f96-4fba-b12e-98b3bc8df099"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/tesi2\n"
     ]
    }
   ],
   "source": [
    "%cd  drive/MyDrive/tesi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "sEg91SvZUuC9",
    "outputId": "a5e28d5d-b569-4b69-96e9-d86622749f04"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content/drive/MyDrive/tesi2'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_B1sKuqoUZd2",
    "outputId": "3874360c-1e23-4f35-df93-ad7a7081006a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mcontent\u001b[0m/\n",
      "\u001b[01;34mdrive\u001b[0m/\n",
      "\u001b[01;34mdropped\u001b[0m/\n",
      "\u001b[01;34mdropped_impressionist\u001b[0m/\n",
      "GAN.ipynb\n",
      "gan_landscapes.h5\n",
      "\u001b[01;34mimage_resized128\u001b[0m/\n",
      "\u001b[01;34mimages\u001b[0m/\n",
      "\u001b[01;34mimages_R\u001b[0m/\n",
      "\u001b[01;34mimpressionist_landscape_1024\u001b[0m/\n",
      "\u001b[01;34mimpressionist_landscapes\u001b[0m/\n",
      "impressionistlandscapespaintings.zip\n",
      "\u001b[01;34mimpressionist_landscapes_resized_1024\u001b[0m/\n",
      "kaggle.json\n",
      "\u001b[01;34mModels\u001b[0m/\n",
      "\u001b[01;34moutput\u001b[0m/\n",
      "\u001b[01;34moutput2\u001b[0m/\n",
      "\u001b[01;34moutput_landscapes\u001b[0m/\n",
      "\u001b[01;34moutput_landscapes50\u001b[0m/\n",
      "\u001b[01;34moutput_landscapes50_rev\u001b[0m/\n",
      "\u001b[01;34mresized128\u001b[0m/\n",
      "\u001b[01;34mresized256\u001b[0m/\n",
      "\u001b[01;34mResults\u001b[0m/\n",
      "the-metropolitan-museum-of-art-ukiyoe-dataset.zip\n",
      "training_data128_new.npy\n",
      "training_data128.npy\n",
      "training_data256_new.npy\n",
      "training_data_256.npy\n",
      "training_data256.npy\n",
      "training_data_landscapes_128.npy\n",
      "training_data.npy\n",
      "trn_data.pkl\n"
     ]
    }
   ],
   "source": [
    "%ls ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "weehAzj0gpwe",
    "outputId": "5780a5b3-eda1-4e6c-ec20-3fc8e9390bd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.1.0\n",
      "  Downloading tensorflow-2.1.0-cp37-cp37m-manylinux2010_x86_64.whl (421.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 421.8 MB 24 kB/s \n",
      "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (3.3.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (0.8.1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (1.21.5)\n",
      "Collecting tensorboard<2.2.0,>=2.1.0\n",
      "  Downloading tensorboard-2.1.1-py3-none-any.whl (3.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.8 MB 34.8 MB/s \n",
      "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (1.1.0)\n",
      "Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n",
      "  Downloading tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448 kB)\n",
      "\u001b[K     |████████████████████████████████| 448 kB 37.1 MB/s \n",
      "\u001b[?25hRequirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (1.4.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (1.15.0)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (3.17.3)\n",
      "Collecting keras-applications>=1.0.8\n",
      "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
      "\u001b[K     |████████████████████████████████| 50 kB 5.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (1.0.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (1.13.3)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (1.43.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (0.37.1)\n",
      "Collecting gast==0.2.2\n",
      "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (1.1.2)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (0.2.0)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==2.1.0) (3.1.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.35.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2.23.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.3.6)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.6)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (57.4.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (4.2.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (4.11.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.7.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.10.0.2)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2021.10.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.2.0)\n",
      "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow==2.1.0) (1.5.2)\n",
      "Building wheels for collected packages: gast\n",
      "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7554 sha256=f46a72b51355026bf174ab5bf7cd295173961e263d02b6743a98567a041462a8\n",
      "  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
      "Successfully built gast\n",
      "Installing collected packages: tensorflow-estimator, tensorboard, keras-applications, gast, tensorflow\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.8.0\n",
      "    Uninstalling tensorflow-estimator-2.8.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.8.0\n",
      "    Uninstalling tensorboard-2.8.0:\n",
      "      Successfully uninstalled tensorboard-2.8.0\n",
      "  Attempting uninstall: gast\n",
      "    Found existing installation: gast 0.5.3\n",
      "    Uninstalling gast-0.5.3:\n",
      "      Successfully uninstalled gast-0.5.3\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.8.0\n",
      "    Uninstalling tensorflow-2.8.0:\n",
      "      Successfully uninstalled tensorflow-2.8.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-probability 0.16.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\u001b[0m\n",
      "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-2.1.1 tensorflow-2.1.0 tensorflow-estimator-2.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-Sy6wFfdgzR1",
    "outputId": "160c0842-f852-483b-bd1f-a1e67f00d7cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras==2.3.1\n",
      "  Downloading Keras-2.3.1-py2.py3-none-any.whl (377 kB)\n",
      "\u001b[?25l\r",
      "\u001b[K     |▉                               | 10 kB 18.4 MB/s eta 0:00:01\r",
      "\u001b[K     |█▊                              | 20 kB 22.5 MB/s eta 0:00:01\r",
      "\u001b[K     |██▋                             | 30 kB 16.2 MB/s eta 0:00:01\r",
      "\u001b[K     |███▌                            | 40 kB 11.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████▍                           | 51 kB 5.7 MB/s eta 0:00:01\r",
      "\u001b[K     |█████▏                          | 61 kB 6.7 MB/s eta 0:00:01\r",
      "\u001b[K     |██████                          | 71 kB 7.6 MB/s eta 0:00:01\r",
      "\u001b[K     |███████                         | 81 kB 6.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████▉                        | 92 kB 7.0 MB/s eta 0:00:01\r",
      "\u001b[K     |████████▊                       | 102 kB 7.6 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▌                      | 112 kB 7.6 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▍                     | 122 kB 7.6 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▎                    | 133 kB 7.6 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▏                   | 143 kB 7.6 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████                   | 153 kB 7.6 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▉                  | 163 kB 7.6 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▊                 | 174 kB 7.6 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▋                | 184 kB 7.6 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▌               | 194 kB 7.6 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▍              | 204 kB 7.6 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▏             | 215 kB 7.6 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████             | 225 kB 7.6 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████            | 235 kB 7.6 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▉           | 245 kB 7.6 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▊          | 256 kB 7.6 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▌         | 266 kB 7.6 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▍        | 276 kB 7.6 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▎       | 286 kB 7.6 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▏      | 296 kB 7.6 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████      | 307 kB 7.6 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▉     | 317 kB 7.6 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▊    | 327 kB 7.6 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▋   | 337 kB 7.6 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▌  | 348 kB 7.6 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▍ | 358 kB 7.6 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▏| 368 kB 7.6 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 377 kB 7.6 MB/s \n",
      "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (1.1.2)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (1.4.1)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (3.13)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (1.21.5)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (1.0.8)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (3.1.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (1.15.0)\n",
      "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras==2.3.1) (1.5.2)\n",
      "Installing collected packages: keras\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 2.8.0\n",
      "    Uninstalling keras-2.8.0:\n",
      "      Successfully uninstalled keras-2.8.0\n",
      "Successfully installed keras-2.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install keras==2.3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b3b4iq6iWWgZ",
    "outputId": "623dea6c-f9c4-4f91-a442-7bf841ce427e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading impressionistlandscapespaintings.zip to /content/drive/MyDrive/tesi2\n",
      " 99% 1.00G/1.00G [00:08<00:00, 139MB/s]\n",
      "100% 1.00G/1.00G [00:08<00:00, 131MB/s]\n"
     ]
    }
   ],
   "source": [
    "#! kaggle datasets download robgonsalves/impressionistlandscapespaintings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZtIu8NT5WtoZ",
    "outputId": "0fcfd9e7-9c68-4cb0-ab11-e3a1740a4cfc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /content/drive/MyDrive/tesi2/impressionistlandscapespaintings.zip\n",
      "replace content/drive/MyDrive/impressionist_landscapes_resized_1024/a-y-jackson_a-copse-evening-1918.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
      "replace content/drive/MyDrive/impressionist_landscapes_resized_1024/a-y-jackson_early-spring-quebec-1923.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
     ]
    }
   ],
   "source": [
    "#!unzip /content/drive/MyDrive/tesi2/impressionistlandscapespaintings.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i6kiGs6oypqB",
    "outputId": "7e6bbaf2-52bf-481b-910c-b6d2e08f7ebc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import Input, Reshape, Dropout, Dense, Flatten, BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import os\n",
    "import os.path\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "id": "wbehoOfE32Br",
    "outputId": "ab82e2a6-b2ab-4c10-cc0c-ed6f0cbbb4a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resizing...\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"\\nfor filename in os.listdir(images_path):\\n  path = os.path.join(images_path, filename)\\n  im = Image.open(path)\\n  image = im.convert('RGB')\\n  fake_data.append(np.asarray(image))\\n\\nfor filename in os.listdir(images_path):\\n  path = os.path.join(images_path, filename)\\n  im = Image.open(path)\\n  image = im.convert('RGB')\\n  true_data.append(np.asarray(image))  \\n\\n\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining an image size and image channel\n",
    "# We are going to resize all our images to 128X128 size and since the images are colored images\n",
    "# We are setting our image channels to 3 (RGB)\n",
    "\n",
    "IMAGE_SIZE = 128\n",
    "IMAGE_CHANNELS = 3\n",
    "IMAGE_DIR = '/content/drive/MyDrive/tesi2/impressionist'\n",
    "\n",
    "# Defining image dir path. Change this if you have different directory\n",
    "images_path = IMAGE_DIR\n",
    "\n",
    "training_data = []\n",
    "\n",
    "# Iterating over the images inside the directory and resizing them using\n",
    "# Pillow's resize method.\n",
    "print('resizing...')\n",
    "\"\"\"\n",
    "for filename in os.listdir(images_path):\n",
    "  path = os.path.join(images_path, filename)\n",
    "  im = Image.open(path)\n",
    "  image = im.convert('RGB')\n",
    "  fake_data.append(np.asarray(image))\n",
    "\n",
    "for filename in os.listdir(images_path):\n",
    "  path = os.path.join(images_path, filename)\n",
    "  im = Image.open(path)\n",
    "  image = im.convert('RGB')\n",
    "  true_data.append(np.asarray(image))  \n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "er4f2MLYYbQu",
    "outputId": "3886f4d6-0d99-464f-c362-5a866f09ed93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'DCGAN256'...\n",
      "remote: Enumerating objects: 30, done.\u001b[K\n",
      "remote: Total 30 (delta 0), reused 0 (delta 0), pack-reused 30\u001b[K\n",
      "Unpacking objects: 100% (30/30), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/t0nberryking/DCGAN256.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fp_z8OzUXe-R",
    "outputId": "b5ef6cf4-8d8c-4bc9-bb0a-4b75fea55b6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resizing...\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# image_resizer.py\n",
    "\n",
    "# Defining an image size and image channel\n",
    "# We are going to resize all our images to 128X128 size and since our images are colored images\n",
    "# We are setting our image channels to 3 (RGB)\n",
    "\n",
    "IMAGE_SIZE = 128\n",
    "IMAGE_CHANNELS = 3\n",
    "IMAGE_DIR = '/content/drive/MyDrive/tesi2/resized256'\n",
    "\n",
    "# Defining image dir path. Change this if you have different directory\n",
    "images_path = IMAGE_DIR\n",
    "\n",
    "training_data = []\n",
    "\n",
    "# Iterating over the images inside the directory and resizing them using\n",
    "# Pillow's resize method.\n",
    "print('resizing...')\n",
    "\n",
    "try:\n",
    "    for artist in os.listdir(images_path):\n",
    "      artist_path = os.path.join(images_path,artist)\n",
    "      for file in os.listdir(artist_path):\n",
    "        path = os.path.join(artist_path,file)      \n",
    "        if os.stat(path).st_size == 3727:\n",
    "            pass\n",
    "        else:\n",
    "            im = Image.open(path)\n",
    "            image = im.convert('RGB')\n",
    "            image = image.resize(\n",
    "                (IMAGE_SIZE, IMAGE_SIZE), Image.ANTIALIAS)\n",
    "\n",
    "            training_data.append(np.asarray(image))\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_vS-AvwmLF9A",
    "outputId": "56ebe13f-ff51-40dc-9b8c-2560583e6515"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3313"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SKyvEd-ndQni"
   },
   "outputs": [],
   "source": [
    "training_data = np.reshape(training_data, (-1, IMAGE_SIZE, IMAGE_SIZE, IMAGE_CHANNELS))\n",
    "training_data = training_data/255\n",
    "np.save(os.path.join('/content/drive/MyDrive/tesi2','training_data_landscapes_128'), training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iaSaYuHghqY9"
   },
   "outputs": [],
   "source": [
    "# Defining image dir path. Change this if you have different directory\n",
    "images_path = IMAGE_DIR\n",
    "# Preview image Frame\n",
    "PREVIEW_ROWS = 4\n",
    "PREVIEW_COLS = 7\n",
    "PREVIEW_MARGIN = 1\n",
    "SAVE_FREQ = 500\n",
    "\n",
    "# Size vector to generate images from\n",
    "NOISE_SIZE = 123\n",
    "\n",
    "# Configuration\n",
    "EPOCHS = 50001 # number of iterations\n",
    "BATCH_SIZE = 50\n",
    "\n",
    "GENERATE_RES = 3\n",
    "IMAGE_SIZE = 128  # rows/cols\n",
    "\n",
    "IMAGE_CHANNELS = 3\n",
    "image_shape = (IMAGE_SIZE, IMAGE_SIZE, IMAGE_CHANNELS)\n",
    "\n",
    "#training_data = np.load('/content/drive/MyDrive/tesi2/training_data128.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uRtJF0V0gOIW"
   },
   "outputs": [],
   "source": [
    "def build_discriminator(image_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=3, strides=2,\n",
    "    input_shape=image_shape, padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(64, kernel_size=3, strides=2, padding='same'))\n",
    "    model.add(ZeroPadding2D(padding=((0, 1), (0, 1))))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(128, kernel_size=3, strides=2, padding='same'))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(256, kernel_size=3, strides=1, padding='same'))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(512, kernel_size=3, strides=1, padding='same'))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    input_image = Input(shape=image_shape)\n",
    "    validity = model(input_image)\n",
    "    return Model(input_image, validity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sgBWf_5Zmzr3",
    "outputId": "47f679c8-b764-4f83-9c9c-b6d1ac16afb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "sequential_4 (Sequential)    (None, 1)                 1720385   \n",
      "=================================================================\n",
      "Total params: 1,720,385\n",
      "Trainable params: 1,718,465\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "build_discriminator(image_shape).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "muavD6Y7miNf"
   },
   "outputs": [],
   "source": [
    "def build_generator(noise_size, channels):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(4 * 4 * 256, activation='relu', input_dim=noise_size))\n",
    "    model.add(Reshape((4, 4, 256)))\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(256, kernel_size=3, padding='same'))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(256, kernel_size=3, padding='same'))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Activation('relu'))\n",
    "    for i in range(GENERATE_RES):\n",
    "         model.add(UpSampling2D())\n",
    "         model.add(Conv2D(256, kernel_size=3, padding='same'))\n",
    "         model.add(BatchNormalization(momentum=0.8))\n",
    "         model.add(Activation('relu'))\n",
    "    model.summary()\n",
    "    model.add(Conv2D(channels, kernel_size=3, padding='same'))\n",
    "    model.add(Activation('tanh'))\n",
    "    input = Input(shape=(noise_size,))\n",
    "    generated_image = model(input)\n",
    "    \n",
    "    return Model(input, generated_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qZI0mhcLpwmH",
    "outputId": "c56e13d6-5bae-4c62-cdc2-7849cc144398"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 4096)              507904    \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 32, 32, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2 (None, 64, 64, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 64, 64, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 64, 64, 256)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2 (None, 128, 128, 256)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 128, 128, 256)     590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 128, 128, 256)     1024      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 128, 128, 256)     0         \n",
      "=================================================================\n",
      "Total params: 3,463,424\n",
      "Trainable params: 3,460,864\n",
      "Non-trainable params: 2,560\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator = build_generator(NOISE_SIZE, IMAGE_CHANNELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1nYWRMGkqEJt"
   },
   "outputs": [],
   "source": [
    "discriminator = build_discriminator(image_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zsny7HIIqG3t",
    "outputId": "e7231a0b-36d2-4df4-9c47-079d276db2fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "sequential_6 (Sequential)    (None, 1)                 1720385   \n",
      "=================================================================\n",
      "Total params: 1,720,385\n",
      "Trainable params: 1,718,465\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GajbvllWmXbU"
   },
   "outputs": [],
   "source": [
    "def save_images(cnt, noise):\n",
    "    image_array = np.full((\n",
    "        PREVIEW_MARGIN + (PREVIEW_ROWS * (IMAGE_SIZE + PREVIEW_MARGIN)),\n",
    "        PREVIEW_MARGIN + (PREVIEW_COLS * (IMAGE_SIZE + PREVIEW_MARGIN)), 3),\n",
    "        255, dtype=np.uint8)\n",
    "\n",
    "    generated_images = generator.predict(noise)\n",
    "\n",
    "    #generated_images = 0.5 * generated_images + 0.5\n",
    "\n",
    "    image_count = 0\n",
    "    for row in range(PREVIEW_ROWS):\n",
    "        for col in range(PREVIEW_COLS):\n",
    "            r = row * (IMAGE_SIZE + PREVIEW_MARGIN) + PREVIEW_MARGIN\n",
    "            c = col * (IMAGE_SIZE + PREVIEW_MARGIN) + PREVIEW_MARGIN\n",
    "            image_array[r:r + IMAGE_SIZE, c:c +\n",
    "                        IMAGE_SIZE] = generated_images[image_count] * 255\n",
    "            image_count += 1\n",
    "\n",
    "    output_path = '/content/drive/MyDrive/tesi2/output_landscapes50'\n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "\n",
    "    filename = os.path.join(output_path, f\"trained-{cnt}.png\")\n",
    "    im = Image.fromarray(image_array)\n",
    "    im.save(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wSz4ab8Mg1_M",
    "outputId": "3eb17d77-e9d7-4706-acb9-7c2467e51eff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 4096)              507904    \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_6 (UpSampling2 (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_7 (UpSampling2 (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_8 (UpSampling2 (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 32, 32, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_9 (UpSampling2 (None, 64, 64, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 64, 64, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 64, 64, 256)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_10 (UpSampling (None, 128, 128, 256)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 128, 128, 256)     590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 128, 128, 256)     1024      \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 128, 128, 256)     0         \n",
      "=================================================================\n",
      "Total params: 3,463,424\n",
      "Trainable params: 3,460,864\n",
      "Non-trainable params: 2,560\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n",
      "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 epoch, Discriminator accuracy: 20.000000298023224, Generator accuracy: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 epoch, Discriminator accuracy: 56.00000023841858, Generator accuracy: 5.999999865889549\n",
      "1000 epoch, Discriminator accuracy: 62.00000047683716, Generator accuracy: 18.000000715255737\n",
      "1500 epoch, Discriminator accuracy: 50.999999046325684, Generator accuracy: 5.999999865889549\n",
      "2000 epoch, Discriminator accuracy: 61.000001430511475, Generator accuracy: 7.999999821186066\n",
      "2500 epoch, Discriminator accuracy: 56.99999928474426, Generator accuracy: 5.999999865889549\n",
      "3000 epoch, Discriminator accuracy: 49.000000953674316, Generator accuracy: 3.999999910593033\n",
      "3500 epoch, Discriminator accuracy: 63.999998569488525, Generator accuracy: 7.999999821186066\n",
      "4000 epoch, Discriminator accuracy: 63.999998569488525, Generator accuracy: 18.000000715255737\n",
      "4500 epoch, Discriminator accuracy: 71.00000381469727, Generator accuracy: 15.999999642372131\n",
      "5000 epoch, Discriminator accuracy: 67.99999475479126, Generator accuracy: 10.000000149011612\n",
      "5500 epoch, Discriminator accuracy: 52.99999713897705, Generator accuracy: 3.999999910593033\n",
      "6000 epoch, Discriminator accuracy: 69.9999988079071, Generator accuracy: 5.999999865889549\n",
      "6500 epoch, Discriminator accuracy: 71.00000381469727, Generator accuracy: 3.999999910593033\n",
      "7000 epoch, Discriminator accuracy: 63.999998569488525, Generator accuracy: 11.999999731779099\n",
      "7500 epoch, Discriminator accuracy: 79.99999523162842, Generator accuracy: 11.999999731779099\n",
      "8000 epoch, Discriminator accuracy: 75.0, Generator accuracy: 5.999999865889549\n",
      "8500 epoch, Discriminator accuracy: 73.00000190734863, Generator accuracy: 14.000000059604645\n",
      "9000 epoch, Discriminator accuracy: 79.00000214576721, Generator accuracy: 20.000000298023224\n",
      "9500 epoch, Discriminator accuracy: 58.000004291534424, Generator accuracy: 21.99999988079071\n",
      "10000 epoch, Discriminator accuracy: 86.00000143051147, Generator accuracy: 7.999999821186066\n",
      "10500 epoch, Discriminator accuracy: 75.99999904632568, Generator accuracy: 5.999999865889549\n",
      "11000 epoch, Discriminator accuracy: 89.99999761581421, Generator accuracy: 18.000000715255737\n",
      "11500 epoch, Discriminator accuracy: 82.00000524520874, Generator accuracy: 0.0\n",
      "12000 epoch, Discriminator accuracy: 87.00000047683716, Generator accuracy: 3.999999910593033\n",
      "12500 epoch, Discriminator accuracy: 75.99999904632568, Generator accuracy: 5.999999865889549\n",
      "13000 epoch, Discriminator accuracy: 81.00000023841858, Generator accuracy: 3.999999910593033\n",
      "13500 epoch, Discriminator accuracy: 87.00000047683716, Generator accuracy: 5.999999865889549\n",
      "14000 epoch, Discriminator accuracy: 93.99999976158142, Generator accuracy: 0.0\n",
      "14500 epoch, Discriminator accuracy: 90.99999666213989, Generator accuracy: 1.9999999552965164\n",
      "15000 epoch, Discriminator accuracy: 86.00000143051147, Generator accuracy: 3.999999910593033\n",
      "15500 epoch, Discriminator accuracy: 87.99999952316284, Generator accuracy: 10.000000149011612\n",
      "16000 epoch, Discriminator accuracy: 90.99999666213989, Generator accuracy: 1.9999999552965164\n",
      "16500 epoch, Discriminator accuracy: 89.99999761581421, Generator accuracy: 0.0\n",
      "17000 epoch, Discriminator accuracy: 93.00000071525574, Generator accuracy: 7.999999821186066\n",
      "17500 epoch, Discriminator accuracy: 92.99999475479126, Generator accuracy: 11.999999731779099\n",
      "18000 epoch, Discriminator accuracy: 79.99999523162842, Generator accuracy: 5.999999865889549\n",
      "18500 epoch, Discriminator accuracy: 87.00000047683716, Generator accuracy: 0.0\n",
      "19000 epoch, Discriminator accuracy: 94.9999988079071, Generator accuracy: 1.9999999552965164\n",
      "19500 epoch, Discriminator accuracy: 92.99999475479126, Generator accuracy: 3.999999910593033\n",
      "20000 epoch, Discriminator accuracy: 91.99999570846558, Generator accuracy: 7.999999821186066\n",
      "20500 epoch, Discriminator accuracy: 88.99999856948853, Generator accuracy: 1.9999999552965164\n",
      "21000 epoch, Discriminator accuracy: 92.99999475479126, Generator accuracy: 1.9999999552965164\n",
      "21500 epoch, Discriminator accuracy: 87.99999952316284, Generator accuracy: 0.0\n",
      "22000 epoch, Discriminator accuracy: 92.99999475479126, Generator accuracy: 0.0\n",
      "22500 epoch, Discriminator accuracy: 84.00000333786011, Generator accuracy: 3.999999910593033\n",
      "23000 epoch, Discriminator accuracy: 93.99999976158142, Generator accuracy: 3.999999910593033\n",
      "23500 epoch, Discriminator accuracy: 90.99999666213989, Generator accuracy: 5.999999865889549\n",
      "24000 epoch, Discriminator accuracy: 94.9999988079071, Generator accuracy: 3.999999910593033\n",
      "24500 epoch, Discriminator accuracy: 95.99999785423279, Generator accuracy: 3.999999910593033\n",
      "25000 epoch, Discriminator accuracy: 89.99999761581421, Generator accuracy: 7.999999821186066\n",
      "25500 epoch, Discriminator accuracy: 89.99999761581421, Generator accuracy: 3.999999910593033\n",
      "26000 epoch, Discriminator accuracy: 87.99999952316284, Generator accuracy: 3.999999910593033\n",
      "26500 epoch, Discriminator accuracy: 90.99999666213989, Generator accuracy: 1.9999999552965164\n",
      "27000 epoch, Discriminator accuracy: 93.00000071525574, Generator accuracy: 3.999999910593033\n",
      "27500 epoch, Discriminator accuracy: 99.00000095367432, Generator accuracy: 5.999999865889549\n",
      "28000 epoch, Discriminator accuracy: 98.00000190734863, Generator accuracy: 5.999999865889549\n",
      "28500 epoch, Discriminator accuracy: 89.99999761581421, Generator accuracy: 0.0\n",
      "29000 epoch, Discriminator accuracy: 94.9999988079071, Generator accuracy: 3.999999910593033\n",
      "29500 epoch, Discriminator accuracy: 97.00000286102295, Generator accuracy: 10.000000149011612\n",
      "30000 epoch, Discriminator accuracy: 90.99999666213989, Generator accuracy: 10.000000149011612\n",
      "30500 epoch, Discriminator accuracy: 95.00000476837158, Generator accuracy: 0.0\n",
      "31000 epoch, Discriminator accuracy: 93.99999976158142, Generator accuracy: 5.999999865889549\n",
      "31500 epoch, Discriminator accuracy: 93.99999976158142, Generator accuracy: 1.9999999552965164\n",
      "32000 epoch, Discriminator accuracy: 88.99999856948853, Generator accuracy: 3.999999910593033\n",
      "32500 epoch, Discriminator accuracy: 90.99999666213989, Generator accuracy: 3.999999910593033\n",
      "33000 epoch, Discriminator accuracy: 90.99999666213989, Generator accuracy: 5.999999865889549\n",
      "33500 epoch, Discriminator accuracy: 89.99999761581421, Generator accuracy: 0.0\n",
      "34000 epoch, Discriminator accuracy: 88.99999856948853, Generator accuracy: 0.0\n",
      "34500 epoch, Discriminator accuracy: 97.00000286102295, Generator accuracy: 0.0\n",
      "35000 epoch, Discriminator accuracy: 87.00000047683716, Generator accuracy: 0.0\n",
      "35500 epoch, Discriminator accuracy: 100.0, Generator accuracy: 3.999999910593033\n",
      "36000 epoch, Discriminator accuracy: 99.00000095367432, Generator accuracy: 0.0\n",
      "36500 epoch, Discriminator accuracy: 97.00000286102295, Generator accuracy: 5.999999865889549\n",
      "37000 epoch, Discriminator accuracy: 96.00000381469727, Generator accuracy: 1.9999999552965164\n",
      "37500 epoch, Discriminator accuracy: 93.99999976158142, Generator accuracy: 7.999999821186066\n",
      "38000 epoch, Discriminator accuracy: 95.00000476837158, Generator accuracy: 1.9999999552965164\n",
      "38500 epoch, Discriminator accuracy: 90.99999666213989, Generator accuracy: 0.0\n",
      "39000 epoch, Discriminator accuracy: 87.00000047683716, Generator accuracy: 1.9999999552965164\n",
      "39500 epoch, Discriminator accuracy: 93.99999976158142, Generator accuracy: 1.9999999552965164\n",
      "40000 epoch, Discriminator accuracy: 97.00000286102295, Generator accuracy: 5.999999865889549\n",
      "40500 epoch, Discriminator accuracy: 94.9999988079071, Generator accuracy: 7.999999821186066\n",
      "41000 epoch, Discriminator accuracy: 93.00000071525574, Generator accuracy: 3.999999910593033\n",
      "41500 epoch, Discriminator accuracy: 88.99999856948853, Generator accuracy: 3.999999910593033\n",
      "42000 epoch, Discriminator accuracy: 86.00000143051147, Generator accuracy: 1.9999999552965164\n",
      "42500 epoch, Discriminator accuracy: 92.00000166893005, Generator accuracy: 1.9999999552965164\n",
      "43000 epoch, Discriminator accuracy: 94.9999988079071, Generator accuracy: 3.999999910593033\n",
      "43500 epoch, Discriminator accuracy: 95.00000476837158, Generator accuracy: 0.0\n",
      "44000 epoch, Discriminator accuracy: 96.00000381469727, Generator accuracy: 0.0\n",
      "44500 epoch, Discriminator accuracy: 96.00000381469727, Generator accuracy: 3.999999910593033\n",
      "45000 epoch, Discriminator accuracy: 94.9999988079071, Generator accuracy: 0.0\n",
      "45500 epoch, Discriminator accuracy: 85.00000238418579, Generator accuracy: 7.999999821186066\n",
      "46000 epoch, Discriminator accuracy: 97.00000286102295, Generator accuracy: 1.9999999552965164\n",
      "46500 epoch, Discriminator accuracy: 95.99999785423279, Generator accuracy: 1.9999999552965164\n",
      "47000 epoch, Discriminator accuracy: 99.00000095367432, Generator accuracy: 5.999999865889549\n",
      "47500 epoch, Discriminator accuracy: 94.9999988079071, Generator accuracy: 0.0\n",
      "48000 epoch, Discriminator accuracy: 93.00000071525574, Generator accuracy: 0.0\n",
      "48500 epoch, Discriminator accuracy: 88.99999856948853, Generator accuracy: 1.9999999552965164\n",
      "49000 epoch, Discriminator accuracy: 93.99999976158142, Generator accuracy: 3.999999910593033\n",
      "49500 epoch, Discriminator accuracy: 90.99999666213989, Generator accuracy: 1.9999999552965164\n",
      "50000 epoch, Discriminator accuracy: 100.0, Generator accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "image_shape = (IMAGE_SIZE, IMAGE_SIZE, IMAGE_CHANNELS)\n",
    "\n",
    "optimizer = Adam(1.5e-4, 0.5)\n",
    "\n",
    "discriminator = build_discriminator(image_shape)\n",
    "discriminator.compile(loss=\"binary_crossentropy\",\n",
    "                      optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "generator = build_generator(NOISE_SIZE, IMAGE_CHANNELS)\n",
    "\n",
    "random_input = Input(shape=(NOISE_SIZE,))\n",
    "\n",
    "generated_image = generator(random_input)\n",
    "\n",
    "discriminator.trainable = False\n",
    "\n",
    "validity = discriminator(generated_image)\n",
    "\n",
    "\n",
    "#def wasserstein_loss(y_true, y_pred):\n",
    "#    \"\"\"Calculates the Wasserstein loss - critic maximises the distance between its output for real and generated samples.\n",
    "#    To achieve this generated samples have the label -1 and real samples the label 1. Multiplying the outputs by the labels results to the wasserstein loss via the Kantorovich-Rubinstein duality\"\"\"\n",
    "#    return K.mean(y_true * y_pred)\n",
    "\n",
    "combined = Model(random_input, validity)\n",
    "combined.compile(loss=\"binary_crossentropy\",\n",
    "                 optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "\n",
    "y_real = np.ones((BATCH_SIZE, 1))\n",
    "y_fake = np.zeros((BATCH_SIZE, 1))\n",
    "\n",
    "fixed_noise = np.random.normal(0, 1, (PREVIEW_ROWS * PREVIEW_COLS, NOISE_SIZE))\n",
    "cnt = 1\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    idx = np.random.randint(0, training_data.shape[0], BATCH_SIZE)\n",
    "    x_real = training_data[idx]\n",
    "\n",
    "    noise = np.random.normal(0, 1, (BATCH_SIZE, NOISE_SIZE))\n",
    "    x_fake = generator.predict(noise)\n",
    "\n",
    "    discriminator_metric_real = discriminator.train_on_batch(x_real, y_real)\n",
    "\n",
    "    discriminator_metric_generated = discriminator.train_on_batch(\n",
    "        x_fake, y_fake)\n",
    "\n",
    "    discriminator_metric = 0.5 * \\\n",
    "        np.add(discriminator_metric_real, discriminator_metric_generated)\n",
    "\n",
    "    generator_metric = combined.train_on_batch(noise, y_real)\n",
    "    if epoch % SAVE_FREQ == 0:\n",
    "        save_images(cnt, fixed_noise)\n",
    "        cnt += 1\n",
    "\n",
    "        print(f\"{epoch} epoch, Discriminator accuracy: {100* discriminator_metric[1]}, Generator accuracy: {100 * generator_metric[1]}\")\n",
    "        generator.save(os.path.join('/content/drive/MyDrive/tesi2/output_landscapes50', \"modern_art_generator.h5\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_QP5h7btHPXe"
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import os.path\n",
    "import numpy as np\n",
    "import PIL\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XUiTTPPruZVj"
   },
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "for file in os.listdir('/content/drive/MyDrive/tesi2/output_landscapes50'):\n",
    "  path = os.path.join(\"/content/drive/MyDrive/tesi2/output_landscapes50\",file)\n",
    "  im = Image.open(path)\n",
    "  image = im.convert('RGB')\n",
    "  im_array = np.asarray(image)\n",
    "  im_array = ((im_array/255.0)-0.5)/0.5\n",
    "  im = Image.fromarray((im_array * 255).astype(np.uint8))\n",
    "  im.save(os.path.join(\"/content/drive/MyDrive/tesi2/output_landscapes50_rev\",f\"trained-{cnt}.png\"))\n",
    "  cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "dr_1N-9zI8ez",
    "outputId": "5ec111e4-f0b3-4f76-b604-f35e99d81985"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'trained-1.png'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('/content/drive/MyDrive/tesi2/output_landscapes50')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JRv564GuwGYc"
   },
   "outputs": [],
   "source": [
    "generator.save(os.path.join('/content/drive/MyDrive/tesi2/output', \"art_generator.h5\"))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "25P38JgWSYbZ"
   ],
   "name": "GAN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1f1a7ec46c5c4ba1b46fbe87c983766f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bb94f3db4db84d48989b96a7344c7c87",
      "max": 117,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c0caa93e0a3649828460b451896d5936",
      "value": 0
     }
    },
    "28e3923823a24205a7f5bcdec6bf82aa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "506a129047114a9a85f87f48a874d4a9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "558a895ce793460aa0f2d9d2f0b796ad": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "70a532ed44924bef87fb76494cfb7119": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "87de2c9f25c544508319e166f87c9682": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_506a129047114a9a85f87f48a874d4a9",
      "placeholder": "​",
      "style": "IPY_MODEL_c1d011022ffb426ca60b3c4bf4895903",
      "value": " 0/117 [00:02&lt;?, ?it/s]"
     }
    },
    "ba7a5b9319f34774aaff307fe7096413": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_558a895ce793460aa0f2d9d2f0b796ad",
      "placeholder": "​",
      "style": "IPY_MODEL_70a532ed44924bef87fb76494cfb7119",
      "value": "  0%"
     }
    },
    "bb94f3db4db84d48989b96a7344c7c87": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c0caa93e0a3649828460b451896d5936": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c1d011022ffb426ca60b3c4bf4895903": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ed199335635e45768efc5660605d5fc6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ba7a5b9319f34774aaff307fe7096413",
       "IPY_MODEL_1f1a7ec46c5c4ba1b46fbe87c983766f",
       "IPY_MODEL_87de2c9f25c544508319e166f87c9682"
      ],
      "layout": "IPY_MODEL_28e3923823a24205a7f5bcdec6bf82aa"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
